---
title: "Modélisation Prédictive Rapport"
author: "Valentin Gölz, Laura Fuentes"
date: "February 28, 2023"
output:
  html_document:
    df_print: paged
  pdf_document: 
    toc : true
    template: default
---
\newpage
# Introduction
Nous avons un jeu de données regroupant différentes variables en rapport avec la consommation énergétique française pendant la période de 2012 à 2021. Notre but est de construire un modèle qui permet de prédire la consommation française en énergie pendant la période du Covid. 

Le premier réflexe est de télécharger l'ensemble des packages et diviser le set train en deux pour pouvoir tester nos modèles avant de les soumettre. Nous avons ainsi choisi la période de 2012 - 2019 comme train et 2019-(15/04/2020) comme test.

```{r preparation, include=FALSE}
rm(list=objects())
library(mgcv)
library(yarrr)
library(qgam)
library(magrittr)
library(forecast)
library(tidyverse)
library(ranger)
library(opera)

rmse = function(y, ychap, digits=0){
  return(round(sqrt(mean((y-ychap)^2, na.rm=TRUE)), digits=digits))
}

###Load Datasets
load("../Data/Data0.Rda")
load("../Data/Data1.Rda")

Data_train = Data0
Data_test = Data1
Data_train$Time <- as.numeric(Data_train$Date)
Data_test$Time <- as.numeric(Data_test$Date)
names(Data_train)
names(Data_test)
dim(Data_train)
dim(Data_test)

#Faire des train et test à partir de Data0
sel_a <- which(Data_train$Year<=2019)
sel_b <- which(Data_train$Year>2019)

Data0 <- Data_train[sel_a, ]
Data1 <- Data_train[sel_b, ]
#Data_test = add_column(Data_test, Load=lead(Data_test$Load.1, default=mean(Data_test$Load.1)), .after = "Date")


```


# Choix du type de modèle 

Pour commencer, nous avons créé tout d'abord, la variable **WeekDays2**. Il s'agit d'une version modifiée de la variable WeekDays qui distingue les jours laboraux, samedis et dimanches. Nous avons d'autre part récupéré des données des différents mouvements sociaux et le pourcentage de population mobilisée. Pendant les jours avec des manifestations, **Movement** est 1 et 0 sinon. Les données viennent de SNCF. Ensuite nous avons créé une variable mesurant la température ressentie. Le problème de cette dernière variable concernait les nombreuses valeurs NA's, ainsi que la représentativité au niveau national des stations météorologiques constituant les données.


Pour comprendre quelles variables sont plus significatives, et argumenter le choix, nous allons effectuer une random forest, et regarder l'importance des variables.
````{r Choix des variables avec random forest}
equation <- "Load~  Time + toy + Temp + Load.1 + Load.7 + Temp_s99 + WeekDays + BH + Temp_s95_max + 
  Temp_s99_max + Summer_break  + Christmas_break + 
  Temp_s95_min +Temp_s99_min + DLS + GovernmentResponseIndex + TauxPopMovement + Movement + HI + WD"
rf <- ranger(equation, data=Data0, importance =  'permutation')

#############importance plot
imp <- rf$variable.importance
imp <- sort(imp)
o <- order(imp, decreasing=T)
nom <- names(imp)
plot(c(1:length(imp)), imp[o], type='h', ylim = c(0, max(imp) + max(imp)/5), xlab='', ylab='Importance (permutation)')
K <- length(imp)
text(tail(c(1:length(imp)), K), tail(imp[o]+max(imp/8), K), labels= tail(nom[o], K), pos=3, srt=90, adj=1, cex=0.6)
points(c(1:length(imp)), imp[o], pch=20)
````

Nous pouvons ainsi bien remarquer que les variables à plus forte importance sont: 
Load.1, Load.7, les variables relatives à la température, WeekDays, WD, BH, toy, Summer_break, DLS and Christmas_break. Nous avons également vérifié que la variable **Movement** (=taux de la population qui a manifesté) n’était pas explicative à l’aide de ANOVA.
```{r}
formula1 <- "Load ~ Temp + WeekDays + WD + BH+ toy + Summer_break + DLS + Christmas_break"
formula2 <- "Load ~ Temp + WeekDays + WD + BH+ toy + Summer_break + DLS + Christmas_break + Movement"
small_lm <- lm(formula1%>%as.formula, data=Data0)
large_lm <- lm(formula2%>%as.formula, data=Data0)
anova.res <- anova(small_lm, large_lm)
summary(anova.res)
```

## Linear Models
### Simple linear model 
Pour comprendre et appréhender le cadre d'étude nous commencerons par effectuer un modèle simple. C'est-à-dire un modèle linéaire avec les co-variables choisies précédemment. Nous avons considéré que la consommation de la veille changeait en fonction du jour de la semaine. C'est pour cela que nous avons décidé de créer une fonction de la consommation de la veille en fonction de chaque catégorie de **WeekDays**.
```{r Linear Models, echo=TRUE}
formula <- "Load ~Load.1 + WeekDays + Load.7 + Temp  + Temp_s99_max + Temp_s99_min + WeekDays + WD + BH+ toy + Summer_break + DLS + Christmas_break + HI "
slm <- lm(formula%>%as.formula, data=Data0)
pred = predict(slm, newdata=Data1)

plot(Data1$Date, Data1$Load, type='l')
lines(Data1$Date,pred, type='l', col='red')
rmse(Data1$Load, pred)
```

### Polynomial transformations
Nous avons mis en place des transformations polynomiales sur le modèle linéaire comme une première approche de complexification du modèle.  Pour cela, nous avons ajouté les co-variables relatives à la température  et Load.7 au carré.

```{r Linear Models avec transformations polynomiales, echo=TRUE}
formula <- "Load ~Load.1 + WeekDays + Load.7 + I(Load.7^2) + Temp + I(Temp^2) + Temp_s99_max + I(Temp_s99_max^2) + Temp_s99_min + WeekDays + WD + BH+ toy + Summer_break + DLS + Christmas_break + HI "
slm <- lm(formula%>%as.formula, data=Data0)
pred = predict(slm, newdata=Data1) #2153

plot(Data1$Date,Data1$Load, type='l')
lines(Data1$Date,pred, type='l', col='red')
rmse(Data1$Load, pred)
```

## Random Forest
```{r Random forest, include=TRUE}
formule <- "Load ~ Month + Temp_s95_min + Temp_s95_max + HI + TauxPopMovement +Time + toy + Temp + Load.1 + Load.7 + WD + BH + Temp_s99_min + Temp_s99_max + Summer_break  + Christmas_break  + DLS"

rf<- ranger::ranger(formule, data = Data0, importance =  'permutation')
rf.forecast <- predict(rf, data = Data1)$predictions

plot(Data1$Date,Data1$Load, type='l')
lines(Data1$Date,rf.forecast, type='l', col='red')
rmse(Data1$Load, rf.forecast)
```

## Modèles additifs généralisés
### Choix de la partie linéaire et spline 

Dans la suite, nous avons considéré de mettre en place des Modèles Additifs généralisés. Pour cela, nous avons d'abord distingué les variables à mettre dans la partie linéaire du modèle, puis dans la partie spline. Nous avons intégré les variables qualitatives ainsi que la consommation de la veille en fonction du jour de la semaine dans la partie linéaire. On a ajouté dans la partie spline les variables ayant une notion de temporalité comme la consommation de la semaine ou les températures. Nous avons également regroupé dans une même spline des variables ayant une relation logique, comme c'était le cas avec la température et le temps. Nous avons également créé une fonction spline pour chaque jour de la semaine pour la variable toy pour ne pas négliger l'effet des jours de la semaine sur la consommation annuelle. 

```{r GAM, include=TRUE}
mod <- gam(Load ~ Load.1:as.factor(WeekDays) + BH + Christmas_break
             + Summer_break + DLS + s(Temp) + s(Temp_s99_max, Temp_s99_min)
             + s(Load.7) + s(Time, k=7) + s(toy, k =30, bs = "cc", by=as.factor(WD))
             + s(Temp, Time, k=20), 
             data=Data_train)

gam.pred <- predict(mod, Data_test)

```
Pour améliorer le rendement du modèle, nous avons tenté de comprendre l'origine des erreurs à partir des courbes de consommation. Nous avons constaté que les erreurs commencent à s'accentuer au niveau du mois de mars 2020, juste au niveau du début de la période covid. Ceci s'explique du fait que la variable **GovernementResponseIndex** comprend des valeurs nulles pendant des années, et celles-ci explosent dans une courte période d'un mois, laissant peu de temps d'entraînement sur la pandémie. Pour simuler le comportement de la population pendant le confinement avec les données que l'on avait déjà, nous avons pensé aux samedis. En effet, nous avons émis l'hypothèse qu'un jour de confinement était comparable en termes de consommation à un jour de weekend comme un samedi. Dans cet esprit, nous avons créé la variable WD, qui modifie le jour de la semaine à samedi s'il y a confinement (la GovernementResponseIndex>=70), et maintien le jours de la semaine inchangé sinon. !! -> mettre online-learning

Nous avons également utilisé la fonction gam.check pour améliorer le rendement du modèle gam. Celle-ci nous a permis d'ajuster la dimension des bases des splines. Nous avons ainsi incrémenter les valeurs de k quand la p-value était très petite. Pour la variable toy, utiliser un k très grand faisait tourner le modèle trop long, nous avons donc pris k=30 même si la p-value était encore petite. Enfin, nous avons également vérifié que les résidus étaient bien gaussiens à chaque fois à partir de l'histogramme issu du plot. 
```{r gam.check, include=TRUE}
gam.check(mod)
```
### GAM et régression quantile: qgam

Dans la suite on utilisera le package qgam, et en particulier la fonction qgam. Celle-ci ajuste un modèle additif ainsi qu'une régression quantile sur un unique quantile. On utilise ici la même équation qu'auparavant, il suffit juste d'ajuster la variable "qu", correspondant au quantile. Après plusieurs essais, nous avons remarqué qu'on obtient de meilleurs résultats avec ‘qu' autour de 0.4. En effet, en fixant le quantile à 0.4, on change la fonction de perte. On introduit ainsi un biais, qui permet de s'ajuster mieux aux données lors de la période du covid.  
```{r qgam , include=TRUE}

equation <- "Load ~ Load.1:as.factor(WeekDays) + HI + BH + Christmas_break + Summer_break + DLS + s(Temp) + s(Temp_s99_max, Temp_s99_min)+ s(Load.7) + s(Time, k=7) + s(toy, k =30, bs = 'cc', by=as.factor(WD))+ s(Temp, Time, k=20)"

gam9<-qgam(equation%>%as.formula, data=Data0, qu=0.4)
gam9.forecast <- predict(gam9, newdata=Data1)

plot(Data1$Date,Data1$Load, type='l')
lines(Data1$Date,gam9.forecast, type='l', col='red')
rmse(Data1$Load, gam9.forecast)
```

## ARIMA et Kalman Filter

### ARIMA
ARIMA (Autoregressive Integrated Moving Average) est un modèle de série chronologique qui utilise les valeurs et les erreurs passées pour prévoir les valeurs futures d'une série. Le modèle peut être ajusté pour capturer les tendances et la saisonnalité, et implique de différencier les données pour les rendre stationnaires. L'ARIMA est largement utilisé pour faire des prévisions sur la base de tendances historiques.

```{r arima , include=TRUE} 
arima.fit <- forecast::Arima(gam9.forecast, order = c(1,1,2), seasonal = c(0,0,2))
arima.predict <- fitted(arima.fit)

plot(Data1$Date, Data1$Load, type='l')
lines(Data1$Date, arima.predict, col="red")
rmse(arima.predict, Data1$Load)
```
### Filtre Kalman 
Une fois le modèle qgam amélioré le modèle qgam, nous avons décidé d’implémenter le online-learning. En effet, comme nous l’avons mentionné précédemment, le problème majeur concernant la variable GovernmentResponseIndex . 
pbl de la variable GRI 
création de GRI_factor 
application de l’algorithme de online learning: filtre de kalman: 
Le modèle met à jour l’estimation des poids sequentiellement au fur et mesure des prédictions 
Keep track of the notation of the subscripts in the equations. The current time step is denoted as n (the timestep for which we want to make a prediction).


## Pipeline basée sur le modèle qgam
Étant arrivés au bout des améliorations de qgam, nous avons considéré d'autres modèles vus en cours pour comparer les performances. 
On a ainsi décidé de garder notre équation sur la qgam et de l'implémenter ensuite sur d'autres modèles. On a ainsi étudié les résidus. Ceci va ainsi nous permettre de ???? \\
Nous avons ainsi décidé de tester les forêts aléatoires sur les résidus de qgam. Après avoir appliqué l'effet des forêts aléatoires sur le modèle, nous avons amélioré davantage la performance à l'aide de Arima. 

```{r QGAM + Blocks résiduals + RF + Arima et validation croisée, include=TRUE}

Nblock<-10
borne_block<-seq(1, nrow(Data_train), length=Nblock+1)%>%floor
block_list<-list()
l<-length(borne_block)
for(i in c(2:(l-1)))
{
  block_list[[i-1]] <- c(borne_block[i-1]:(borne_block[i]-1))
}
block_list[[l-1]]<-c(borne_block[l-1]:(borne_block[l]))


blockRMSE<-function(equation, block)
{
  g<- gam(as.formula(equation), data=Data_train[-block,])
  forecast<-predict(g, newdata=Data_train[block,])
  return(forecast)
} 

Block_forecast<-lapply(block_list, blockRMSE, equation=equation)%>%unlist
Block_residuals <- Data_train$Load-Block_forecast

####estimation of GAM, GAM effects
g <- gam9
g.forecast <- predict(g, newdata=Data_test)
terms0 <- predict(g, newdata=Data_train, type='terms')
terms1 <- predict(g, newdata=Data_test, type='terms')
colnames(terms0) <- paste0("gterms_", c(1:ncol(terms0)))
colnames(terms1) <- paste0("gterms_", c(1:ncol(terms1)))

Data0_rf <- data.frame(Data_train, terms0)
residualsCV <- Block_residuals

Data0_rf$residuals <- residualsCV
Data0_rf$res.48 <- c(residualsCV[1], residualsCV[1:(length(residualsCV)-1)])
Data0_rf$res.336 <- c(residualsCV[1:7], residualsCV[1:(length(residualsCV)-7)])

Data_test = add_column(Data_test, Load=lead(Data_test$Load.1, default=mean(Data_test$Load.1)), .after = "Date")
Data1_rf <- data.frame(Data_test, terms1)
residuals <- Data1_rf$Load - gam9.forecast
Data1_rf$residuals <- residuals
Data1_rf$res.48 <- c(residuals[1], residuals[1:(length(residuals)-1)])
Data1_rf$res.336 <- c(residuals[1:7], residuals[1:(length(residuals)-7)])

cov <- "Time + toy + Temp + Load.1 + Load.7 + Temp_s99 + WeekDays + BH + Temp_s95_max + Temp_s99_max + Summer_break  + Christmas_break + 
Temp_s95_min +Temp_s99_min + DLS + GovernmentResponseIndex + res.48 + res.336 +"
gterm <-paste0("gterms_", c(1:ncol(terms0)))
gterm <- paste0(gterm, collapse='+')
cov <- paste0(cov, gterm, collapse = '+')
formule_rf <- paste0("residuals", "~", cov)
rf_gam<- ranger::ranger(formule_rf, data = Data0_rf, importance =  'permutation')
rf_gam.forecast <- predict(rf_gam, data = Data1_rf)$predictions+ g.forecast

rmse(y=Data_test$Load, ychap=rf_gam.forecast)
rf_gam$variable.importance%>%sort


Block_residuals.ts <- ts(Block_residuals, frequency=7)
fit.arima.res <- auto.arima(Block_residuals.ts,max.p=3,max.q=4, max.P=2, max.Q=2, trace=T,ic="aic", method="CSS")
#Best model: ARIMA(1,1,2)(2,0,2)[7]
#saveRDS(fit.arima.res, "Results/tif.arima.res.RDS")
ts_res_forecast <- ts(c(Block_residuals.ts, Data_test$Load-gam9.forecast),  frequency= 7)
refit <- Arima(ts_res_forecast, model=fit.arima.res)
prevARIMA.res <- tail(refit$fitted, nrow(Data_test))
gam9.arima.forecast <- gam9.forecast + prevARIMA.res
```

## Aggrégation d'experts 

Comme dernière méthode, nous avons décidé de mettre en place un agrégation d'experts pour extraire une combinaison de prédicteurs qui puissent améliorer davantage la performance du modèle. Pour cela, nous avons regroupé les différents prédicteurs dans une variable experts. Dans cette agrégation d'experts, nous avons utilisé les différents modèles qgam (avec et sans arima), une forêt aléatoire comprenant toutes les variables, ainsi qu'un filtre kalman. Nous avions déjà essayé un tel élément, mais les résultats n'étaient pas assez satisfaisants.  
Le modèle obtenu par combinaison des différents prédicteurs obtient une performance bien meilleure que celle obtenue auparavant. 

```{r QGAM + Blocks résiduals + RF + Arima , include=TRUE}
experts <- cbind(gam9.forecast, gam9.arima.forecast, rf_gam.forecast ,rf.forecast, gam5.forecast, gam6.forecast)%>%as.matrix

Data <- rbind(Data_train, Data_test[,-21])
X <- predict(gam9, newdata=Data, type='terms')
###scaling columns
for (j in 1:ncol(X)){
  X[,j] <- (X[,j]-mean(X[,j])) / sd(X[,j])
}
X <- cbind(X,1)
d <- ncol(X)
y <- Data$Load

ssm <- viking::statespace(X, y)
ssm_dyn = readRDS("Results/smm_dyn.RDS")

ssm_dyn <- predict(ssm_dyn, X, y, type='model', compute_smooth = TRUE)
gam9.kalman.Dyn <- ssm_dyn$pred_mean%>%tail(nrow(Data_test))

experts <- cbind(experts, gam9.kalman.Dyn)
nom_exp <- c("gam", "gamarima", "rf", "rfgam",  "kalman", "gam5", "gam6")
colnames(experts) <-  nom_exp
rmse_exp <- apply(experts, 2, rmse, y=Data_test$Load)
sort(rmse_exp)

cumsum_exp <- apply(Data_test$Load-experts, 2, cumsum)

par(mfrow=c(1,1))
K <-ncol(experts)
col <- rev(RColorBrewer::brewer.pal(n = max(min(K,11),4),name = "Spectral"))[1:min(K,11)]
matplot(cumsum_exp, type='l', col=col, lty=1, lwd=2)
par(new=T)
plot(Data1$GovernmentResponseIndex, lwd=2, type='l', axes=F, ylab='')
legend("bottomleft", col=col, legend=colnames(experts), lty=1, bty='n')


or <- oracle(Y=Data_test$Load, experts)
or

#Gives a pretty nice score: 1502 (best so far) ---> maybe interesting to submit it ?
rmse(or$prediction[1:274], y=Data_test$Load[1:274])

#######bias correction
expertsM2000 <- experts-3000
expertsP2000 <- experts+3000
experts <- cbind(experts, expertsM2000, expertsP2000)
colnames(experts) <-c(nom_exp, paste0(nom_exp,  "M"), paste0(nom_exp,  "P"))


cumsum_exp <- apply(Data_test$Load-experts, 2, cumsum)

par(mfrow=c(1,1))
K <-ncol(experts)
col <- rev(RColorBrewer::brewer.pal(n = max(min(K,11),4),name = "Spectral"))[1:min(K,11)]
matplot(cumsum_exp, type='l', col=col, lty=1, lwd=2)
par(new=T)
plot(Data_test$GovernmentResponseIndex, lwd=2, type='l', axes=F, ylab='')
legend("bottomleft", col=col, legend=colnames(experts), lty=1, bty='n')


or <- oracle(Y=Data_test$Load, expertsP2000)
or

plot(or$prediction, type='l', col='red')
lines(Data_test$Load, type='l')
rmse(Data_test$Load[1:274], or$prediction[1:274])

agg <- mixture(Y = Data_test$Load, experts = experts, model = "BOA", loss.gradient=TRUE)
summary(agg)
plot(agg)

ssm_dyn2 <- ssm_dyn
ssm_dyn2$kalman_params$Q <- ssm_dyn$kalman_params$Q*1000
ssm_dyn2 <- predict(ssm_dyn2, X, y, type='model', compute_smooth = TRUE)
gam9.kalman.Dyn2 <- ssm_dyn2$pred_mean%>%tail(nrow(Data_test))

experts <- cbind(experts, gam9.kalman.Dyn2)
agg <- mixture(Y = Data_test$Load, experts = experts, loss.gradient=TRUE)
summary(agg)
```

%%% A Rajouter les critères utilisés pour des bons modèles. 

# Conclusion

Dans ce travail, nous avons testé plusieurs modèles différents pour prédire la charge électrique de la France. Si nos modèles les plus simples donnaient déjà des résultats exploitables, les plus complexes étaient encore plus prometteurs. Le plus grand défi a été le fait que la période de test a été fixée pendant la pandémie de covid, rendant la prévision plus difficile. Notre meilleur modèle est un modèle additif généralisé avec régression quantile. L'utilisation de techniques telles que l'agrégation d'experts et l'apprentissage en ligne a encore amélioré notre précision.
